{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeledDataset(Dataset):\n",
    "    \"\"\"Face Label dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir,ids, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.imgs = df.iloc[ids,:]\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.imgs['Filename'].iloc[idx])\n",
    "\n",
    "        image = Image.open(img_name)\n",
    "        Label = self.imgs['Label'].iloc[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            Label = torch.tensor(Label)\n",
    "        \n",
    "        sample = {'image': image, 'Label': Label}\n",
    "\n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512 6048\n",
      "   col1  col2\n",
      "0     1     1\n",
      "1     2     2\n",
      "2     3     3\n",
      "   col1  col2\n",
      "0     1     1\n",
      "2     3     3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "## Generate IDs for train-test split\n",
    "train_ids, test_ids = train_test_split(np.arange(0,7560),test_size=0.2,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\OEM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "transformation =  transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = labeledDataset(csv_file=r'kaggle\\input\\deep-learning-for-msc-2022-23\\train.csv',\n",
    "                                           root_dir=r'kaggle\\input\\deep-learning-for-msc-2022-23\\train',\n",
    "                                           ids = train_ids,transform=transformation)\n",
    "\n",
    "test_dataset = labeledDataset(csv_file=r'kaggle\\input\\deep-learning-for-msc-2022-23\\train.csv',\n",
    "                                           root_dir=r'kaggle\\input\\deep-learning-for-msc-2022-23\\train',\n",
    "                                           ids = test_ids,transform=transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "class_names = [0,1,2,3]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion, optimizer, scheduler,num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for item in train_loader:\n",
    "            inputs = item['image']\n",
    "            labels = item['Label']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(1==1):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() /len(train_dataset)\n",
    "        print(f'training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\OEM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "training Loss: 0.7897 Acc: 0.7161\n",
      "Epoch 1/24\n",
      "----------\n",
      "training Loss: 0.7041 Acc: 0.7593\n",
      "Epoch 2/24\n",
      "----------\n",
      "training Loss: 0.5956 Acc: 0.7910\n",
      "Epoch 3/24\n",
      "----------\n",
      "training Loss: 0.5430 Acc: 0.8102\n",
      "Epoch 4/24\n",
      "----------\n",
      "training Loss: 0.5129 Acc: 0.8226\n",
      "Epoch 5/24\n",
      "----------\n",
      "training Loss: 0.4672 Acc: 0.8401\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\University Work\\Masters\\Semester 2\\DeepLearning\\Deep-Learning-Assesment\\transfer.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n",
      "\u001b[1;32md:\\University Work\\Masters\\Semester 2\\DeepLearning\\Deep-Learning-Assesment\\transfer.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Work/Masters/Semester%202/DeepLearning/Deep-Learning-Assesment/transfer.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset  = labeledDataset(csv_file=r'kaggle\\input\\deep-learning-for-msc-2022-23\\example.csv',\n",
    "                                           root_dir=r'kaggle\\input\\deep-learning-for-msc-2022-23\\test',\n",
    "                                           transform=transformation)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "filenames = pd.read_csv(\"kaggle/input/deep-learning-for-msc-2022-23/example.csv\")\n",
    "\n",
    "filenames = filenames['Filename']\n",
    "\n",
    "names = []\n",
    "preds = []\n",
    "\n",
    "for idx, item in enumerate(val_loader):\n",
    "    img_name = filenames[idx]\n",
    "    imgs=item['image']\n",
    "    labels = item['Label']\n",
    "    imgs = imgs.to(device)\n",
    "    output = model(imgs)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    preds.append(pred.numpy()[0][0])\n",
    "    names.append(img_name)\n",
    "    \n",
    "\n",
    "\n",
    "# print(f'The predicted label is{preds.numpy()[0][0]}')\n",
    "\n",
    "data = {'Filename': names, 'Label': preds}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset  = labeledDataset(csv_file=r'kaggle\\input\\deep-learning-for-msc-2022-23\\example.csv',\n",
    "                                           root_dir=r'kaggle\\input\\deep-learning-for-msc-2022-23\\test',\n",
    "                                           transform=transformation)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "filenames = pd.read_csv(\"kaggle/input/deep-learning-for-msc-2022-23/example.csv\")\n",
    "\n",
    "filenames = filenames['Filename']\n",
    "\n",
    "names = []\n",
    "preds = []\n",
    "\n",
    "for idx, item in enumerate(val_loader):\n",
    "    img_name = filenames[idx]\n",
    "    imgs=item['image']\n",
    "    labels = item['Label']\n",
    "    imgs = imgs.to(device)\n",
    "    output = model_ft(imgs)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    preds.append(pred.numpy()[0][0])\n",
    "    names.append(img_name)\n",
    "    \n",
    "    if idx > 100:\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "# print(f'The predicted label is{preds.numpy()[0][0]}')\n",
    "\n",
    "data = {'Filename': names, 'Label': preds}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
